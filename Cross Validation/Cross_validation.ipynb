{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b713b3",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb5751",
   "metadata": {},
   "source": [
    "Cross-validation is a statistical method used to estimate the performance of machine learning models. It is a method for assessing how the results of a statistical analysis will generalize to an independent data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef7a16",
   "metadata": {},
   "source": [
    "## 1. K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc96e1",
   "metadata": {},
   "source": [
    "The training data used in the model is split, into k number of smaller sets, to be used to validate the model. The model is then trained on k-1 folds of training set. The remaining fold is then used as a validation set to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d990b470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [1.         1.         0.83333333 0.93333333 0.8       ]\n",
      "Average CV Score:  0.9133333333333333\n",
      "Number of CV Scores used in Average:  5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "k_folds = KFold(n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = k_folds)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a71a00",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "1. The whole dataset is used as both a training set and validation set:\n",
    "\n",
    "Cons:\n",
    "\n",
    "1. Not to be used for imbalanced datasets:\n",
    "2. Not suitable for Time Series data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75ead4",
   "metadata": {},
   "source": [
    "## 2. HoldOut Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e769a6",
   "metadata": {},
   "source": [
    "In this technique of cross-validation optimization, the whole dataset is randomly partitioned into a training set and validation set. Using a rule of thumb nearly 70% of the whole dataset is used as a training set and the remaining 30% is used as the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79699b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Dataset 150\n",
      "Accuracy score on training set is 0.9619047619047619\n",
      "Accuracy score on test set is 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris=load_iris()\n",
    "X=iris.data\n",
    "Y=iris.target\n",
    "print(\"Size of Dataset {}\".format(len(X)))\n",
    "logreg=LogisticRegression()\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "logreg.fit(x_train,y_train)\n",
    "predict=logreg.predict(x_test)\n",
    "print(\"Accuracy score on training set is {}\".format(accuracy_score(logreg.predict(x_train),y_train)))\n",
    "print(\"Accuracy score on test set is {}\".format(accuracy_score(predict,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dba576",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "1. Quick To Execute:\n",
    "    \n",
    "Cons:\n",
    "\n",
    "1. Not Suitable for an imbalanced dataset:\n",
    "2. A large chunk of data gets deprived of training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a74672e",
   "metadata": {},
   "source": [
    "## 3. Stratified K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9bd49",
   "metadata": {},
   "source": [
    "Stratified K-Fold is an enhanced version of K-Fold cross-validation which is mainly used for imbalanced datasets. Just like K-fold, the whole dataset is divided into K-folds of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9f7aa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.96666667 0.96666667 0.9        0.93333333 1.        ]\n",
      "Average CV Score:  0.9533333333333334\n",
      "Number of CV Scores used in Average:  5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "sk_folds = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = sk_folds)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4648ac6",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "1. Works perfectly well for Imbalanced Data:\n",
    "\n",
    "Cons:\n",
    "\n",
    "1. Not suitable for Time Series data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab6dbc",
   "metadata": {},
   "source": [
    "## 4. Leave-One-Out (LOO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6efa1d5",
   "metadata": {},
   "source": [
    "Instead of selecting the number of splits in the training data set like k-fold LeaveOneOut, utilize 1 observation to validate and n-1 observations to train. This method is an exaustive technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4298512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "Average CV Score:  0.94\n",
      "Number of CV Scores used in Average:  150\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = loo)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a752eae9",
   "metadata": {},
   "source": [
    "We can observe that the number of cross validation scores performed is equal to the number of observations in the dataset. In this case there are 150 observations in the iris dataset.\n",
    "\n",
    "The average CV score is 94%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5626fc",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "1. All the data samples get used as both training and validation samples.\n",
    "\n",
    "Cons:\n",
    "\n",
    "1. High computation time:\n",
    "2. Not Suitable for Imbalanced dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431578ab",
   "metadata": {},
   "source": [
    "## 5. Shuffle Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e1452",
   "metadata": {},
   "source": [
    "Unlike KFold, ShuffleSplit leaves out a percentage of the data, not to be used in the train or validation sets. To do so we must decide what the train and test sizes are, as well as the number of splits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28df0b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.97777778 0.97777778 0.91111111 0.91111111 1.        ]\n",
      "Average CV Score:  0.9555555555555555\n",
      "Number of CV Scores used in Average:  5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "ss = ShuffleSplit(train_size=0.6, test_size=0.3, n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = ss)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a41f66f",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "1. We are free to use the size of the training and validation set.\n",
    "\n",
    "2. We can choose the number of repetitions and not depend on the number of folds for repetitions.\n",
    "\n",
    "Cons:\n",
    "\n",
    "1. Few samples may not be selected for either training or validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c963a7",
   "metadata": {},
   "source": [
    "## 6. Time Series Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f2da5",
   "metadata": {},
   "source": [
    "Time series data is data that is collected at different points in time. As the data points are collected at adjacent time periods there is potential for correlation between observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "406af3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
      "TRAIN: [0] TEST: [1]\n",
      "TRAIN: [0 1] TEST: [2]\n",
      "TRAIN: [0 1 2] TEST: [3]\n",
      "TRAIN: [0 1 2 3] TEST: [4]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "time_series = TimeSeriesSplit()\n",
    "print(time_series)\n",
    "for train_index, test_index in time_series.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b437684",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "1. One of the finest techniques .\n",
    "\n",
    "Cons:\n",
    "\n",
    "1. Not suitable for validation of other data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969622f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
